#' Calculate LOO-CV for a Because Model
#'
#' Calculates Leave-One-Out Cross-Validation using Pareto Smoothed Importance Sampling (PSIS-LOO)
#' for a fitted Because model.
#'
#' @param model A fitted model object of class \code{"because"} returned by \code{\link{because}}.
#'   \strong{Note}: If the model was not fitted with \code{WAIC = TRUE} (so \code{log_lik} is missing),
#'   this function will automatically refit the model (using a short MCMC run) to calculate the likelihoods.
#' @param ...  Additional arguments passed to \code{loo::loo()}.
#'
#' @return A \code{loo} object containing:
#' \item{estimates}{Table with ELPD (expected log pointwise predictive density), LOO-IC, and p_loo}
#' \item{diagnostics}{Pareto k diagnostic values for each observation}
#' \item{pointwise}{Pointwise contributions to LOO-IC}
#'
#' @details
#' LOO-CV (Leave-One-Out Cross-Validation) uses Pareto Smoothed Importance Sampling to approximate
#' leave-one-out predictive performance without refitting the model N times. This is particularly
#' useful for:
#' \itemize{
#'   \item Model comparison when models have different numbers of latent variables
#'   \item Identifying influential observations (via Pareto k diagnostics)
#'   \item Robust predictive performance assessment
#' }
#'
#' **Pareto k diagnostics**:
#' \itemize{
#'   \item k < 0.5: Excellent (all estimates reliable)
#'   \item 0.5 < k < 0.7: Good (estimates okay)
#'   \item 0.7 < k < 1: Problematic (estimates unreliable)
#'   \item k > 1: Very problematic (refit model excluding these observations)
#' }
#'
#' **Note on implementation**:
#' This function extracts the pointwise log-likelihoods calculated by the JAGS model
#' (monitored as \code{log_lik[i]}) when \code{WAIC = TRUE}. It does not re-compute likelihoods
#' from posterior samples in R, ensuring consistency with the fitted model structure.
#'
#' @examples
#' \dontrun{
#'   fit <- because(data, tree, equations, WAIC = TRUE)
#'   loo_result <- because_loo(fit)
#'   print(loo_result)
#'
#'   # Check for problematic observations
#'   plot(loo_result)
#'
#'   # Compare models
#'   loo_compare(loo_result1, loo_result2)
#' }
#'
#' @export
#' @importFrom stats sd dnorm
because_loo <- function(model, ...) {
    if (!inherits(model, "because")) {
        stop("Input must be a 'because' model object.")
    }

    # Extract log_lik using helper (auto-refits if needed)
    log_lik <- ensure_log_lik(model)

    # Calculate LOO
    # Save indices needed for potential refitting? (Not implemented yet)
    loo_result <- loo::loo(log_lik, ...)

    return(loo_result)
}


#' Compare Models Using LOO-CV
#'
#' Wrapper for \code{loo::loo_compare()} to compare multiple Because models.
#'
#' @param ... Two or more \code{loo} objects from \code{because_loo()}.
#'
#' @return A comparison table ranking models by expected out-of-sample predictive accuracy.
#'
#' @examples
#' \dontrun{
#'   loo1 <- because_loo(fit1)
#'   loo2 <- because_loo(fit2)
#'   because_loo_compare(loo1, loo2)
#' }
#'
#' @export
because_loo_compare <- function(...) {
    loo::loo_compare(...)
}
