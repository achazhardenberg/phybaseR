---
title: "Model Diagnostics and Interpretation"
author: "Achaz von Hardenberg"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{09. Model Diagnostics and Interpretation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
    collapse = TRUE,
    comment = "#>"
)
```

# Model Diagnostics and Interpretation

This guide covers testing model fit, checking convergence, comparing models, and interpreting results.

## D-Separation Testing

D-separation tests whether your model structure correctly represents the conditional independencies in your data.

### What is D-Separation?

**D-separation** (directional separation): A method to test if your causal model implies the correct conditional independencies.

**Key idea**: Your DAG implies certain variables should be independent given others. We test if this holds in the data.

### How It Works

```{r, eval=FALSE}
# Your model
equations <- list(
    z ~ x,
    y ~ z
)

# Implied independence: x ⊥ y | z
# "x and y are independent given z"

fit <- phybase_run(
    equations = equations,
    data = data,
    dsep = TRUE # Test d-separation!
)
```

### Reading D-Sep Results

```r
D-separation Tests
==================
              Test     Parameter Estimate LowerCI UpperCI Indep P(~0)
 y _||_ x | {z}  beta_y_x      0.02   -0.05   0.09   Yes   0.68

Legend:
  Indep: 'Yes' = Independent (GOOD!), 'No' = Dependent (check model)
  P(~0): Probability effect crosses zero (want HIGH for d-sep)
```

**Interpretation**:
- **High P(~0)** (>0.5): Independence holds ✅ Model fits!
- **Low P(~0)** (<0.1): Variables are dependent ⚠️ Missing path?

### What D-Sep Tests Tell You

✅ **Test passes** (indep holds): Model structure is consistent with data  
❌ **Test fails** (indep violated): Model is misspecified

**Common reasons for failure**:
1. Missing causal path
2. Reversed causality
3. Unmeasured confounder
4. Wrong conditional set

### Example: Diagnosing Model Problems

```{r, eval=FALSE}
# Hypothesized model
equations <- list(
    range_size ~ body_size,
    population ~ range_size
)

fit <- phybase_run(equations, data, dsep = TRUE)

# D-sep result:
# population _||_ body_size | range_size
# P(~0) = 0.02  ← FAIL!

# Interpretation: body_size affects population even controlling for range_size
# Fix: Add direct path
equations_fixed <- list(
    range_size ~ body_size,
    population ~ range_size + body_size # Added!
)
```

### M-Separation (with Latent Variables)

When latent variables are present, phybaseR uses **m-separation** on the MAG (Maximal Ancestral Graph).

Same interpretation, but accounts for induced correlations from latent confounders.

See **[Latent Variables](latent_variables.html)** vignette for details.

---

## Response Distributions

phybaseR supports different response distributions for different data types.

### Gaussian (Default)

For continuous, normally distributed data:

```{r, eval=FALSE}
fit <- phybase_run(
    equations = list(
        body_mass ~ age + sex
    ),
    data = data,
    distribution = list(body_mass = "gaussian") # Default
)
```

### Binomial (Binary/Proportions)

For binary outcomes (0/1) or proportions (success/trials):

```{r, eval=FALSE}
# Binary: survival (0 = dead, 1 = alive)
fit <- phybase_run(
    equations = list(
        survival ~ age + condition
    ),
    data = data,
    distribution = list(survival = "binomial")
)

# Proportions: hatching success
data$N_trials <- 10 # Clutch size
data$N_success <- ... # Number hatched

fit <- phybase_run(
    equations = list(
        hatching_success ~ temperature
    ),
    data = data,
    distribution = list(hatching_success = "binomial")
)
```

**Model**: Logit link
```
logit(p) = α + βx
p = probability of success
```

### Poisson (Count Data)

For count data (non-negative integers):

```{r, eval=FALSE}
# Number of offspring
fit <- phybase_run(
    equations = list(
        offspring_count ~ age + body_size
    ),
    data = data,
    distribution = list(offspring_count = "poisson")
)
```

**Model**: Log link
```
log(λ) = α + βx
λ = expected count
```

**When to use**: 
- Counts (0, 1, 2, 3, ...)
- No upper limit
- Variance ≈ mean

### Negative Binomial (Overdispersed Counts)

For count data with variance > mean:

```{r, eval=FALSE}
fit <- phybase_run(
    equations = list(
        parasite_load ~ host_size
    ),
    data = data,
    distribution = list(parasite_load = "negbinomial")
)
```

**When to use**:
- Count data
- Overdispersion (variance >> mean)
- More flexible than Poisson

### Gamma (Positive Continuous)

For positive, continuous, right-skewed data:

```{r, eval=FALSE}
fit <- phybase_run(
    equations = list(
        lifespan ~ body_mass
    ),
    data = data,
    distribution = list(lifespan = "gamma")
)
```

**When to use**:
- Positive values only
- Right-skewed
- Examples: lifespans, waiting times, amounts

### Multinomial (Unordered Categorical)

For categorical outcomes with 3+ unordered levels:

```{r, eval=FALSE}
# Habitat choice: Forest, Grassland, Wetland (no inherent order)
data$habitat <- factor(data$habitat,
    levels = c("Forest", "Grassland", "Wetland")
)

fit <- phybase_run(
    equations = list(
        habitat ~ temperature + rainfall
    ),
    data = data,
    distribution = list(habitat = "multinomial")
)
```

**Model**: Multinomial logit (K-1 equations for K categories)
```
log(P(category k) / P(reference)) = α_k + β_k × X
```

**When to use**:
- Categorical outcome with 3+ levels
- Categories have no natural ordering
- Examples: habitat types, color morphs, behavioral states

**Requirements**:
- Response must be a factor
- Minimum 3 categories (use binomial for 2)
- Reference category is first factor level

### Ordinal (Ordered Categorical)

For categorical outcomes with natural ordering:

```{r, eval=FALSE}
# Body condition: Poor < Fair < Good < Excellent
data$condition <- factor(data$condition,
    levels = c("Poor", "Fair", "Good", "Excellent"),
    ordered = TRUE
)

fit <- phybase_run(
    equations = list(
        condition ~ age + food_availability
    ),
    data = data,
    distribution = list(condition = "ordinal")
)
```

**Model**: Cumulative logit (proportional odds)
```
logit(P(Y ≤ k)) = θ_k - β × X
```

**When to use**:
- Categorical outcome with natural ordering
- Want to respect ordering in analysis
- Examples: condition scores, severity levels, Likert scales

**Advantages over multinomial**:
- Fewer parameters (single β instead of K-1)
- More power if ordering is real
- Interpretable as "ordered effect"

**Requirements**:
- Response must be an ordered factor
- Minimum 3 categories
- Proportional odds assumption (effect same across cutpoints)

### Multiple Distributions

Different response variables can have different distributions:

```{r, eval=FALSE}
fit <- phybase_run(
    equations = list(
        survival ~ age, # Binomial
        offspring ~ survival, # Poisson
        body_mass ~ age # Gaussian
    ),
    data = data,
    distribution = list(
        survival = "binomial",
        offspring = "poisson",
        body_mass = "gaussian"
    )
)
```

---

## Convergence Diagnostics

### Rhat (Gelman-Rubin Statistic)

Measures convergence across chains.

**Rule**: Rhat < 1.1 for all parameters

```{r, eval=FALSE}
summary(fit)

# Check Rhat column:
#           Estimate  Rhat
# beta_x      0.45   1.002  ✓ Good
# beta_y      0.32   1.15   ✗ Poor - needs more iterations
```

**If Rhat > 1.1**:
1. Increase iterations: `n.iter = 10000`
2. Increase burn-in: `n.burnin = 5000`
3. More chains: `n.chains = 4`
4. Check for model issues

### Effective Sample Size (n.eff)

Number of independent samples from the posterior.

**Rule**: n.eff > 100 (ideally > 1000)

```{r, eval=FALSE}
# Low n.eff:
#           n.eff
# beta_x      45   ✗ Too low

# Solution: Thin more or run longer
fit <- phybase_run(
    equations, data,
    n.iter = 20000,
    n.thin = 5 # Save every 5th iteration
)
```

### Trace Plots

Visual inspection of MCMC chains:

```{r, eval=FALSE}
# Extract samples
samples <- fit$samples

# Plot traces
plot(samples[, "beta_x"], type = "l")

# Good: "fuzzy caterpillar" - well-mixed, stationary
# Bad: trends, getting stuck, different chains separated
```

---

## Model Comparison

### DIC (Deviance Information Criterion)

Balances fit and complexity.

**Lower is better**

```{r, eval=FALSE}
fit1 <- phybase_run(equations1, data, DIC = TRUE)
fit2 <- phybase_run(equations2, data, DIC = TRUE)

fit1$DIC # 245.3
fit2$DIC # 238.1  ← Better

# Difference > 5-10: Strong evidence for better model
```

### WAIC (Widely Applicable IC)

More robust than DIC, especially for hierarchical models.

**Lower is better**

```{r, eval=FALSE}
fit <- phybase_run(
    equations, data,
    WAIC = TRUE,
    n.chains = 2 # Requires 2+ chains
)

fit$WAIC$WAIC # Overall WAIC
fit$WAIC$lppd # Log pointwise predictive density
```

### Which to Use?

- **Simple models**: DIC is fine
- **Hierarchical/complex**: WAIC preferred
- **Both available**: Report both

**Rule of thumb**: Δ(IC) > 10 is strong evidence

---

## Parameter Interpretation

### Fixed Effects (Betas)

```r
          Estimate LowerCI UpperCI
beta_age    0.45    0.32    0.58
```

**Interpretation**:
- **Estimate**: Expected change in response per unit predictor
- **95% CI**: Range of plausible values
- **Sign**: Positive = positive effect, negative = negative effect

### Credible Intervals

**95% Credible Interval**: 95% probability true value is in this range

**Interpreting**:
- **Doesn't include 0**: "Significant" effect
- **Includes 0**: Inconclusive/no clear effect
- **Width**: Uncertainty (narrow = precise, wide = uncertain)

### Standardized Effects

For comparing effects across variables:

```{r, eval=FALSE}
# Standardize predictors beforehand
data$age_std <- scale(data$age)
data$mass_std <- scale(data$mass)

fit <- phybase_run(
    equations = list(
        survival ~ age_std + mass_std
    ),
    data = data
)

# Now beta estimates are comparable!
```

---

## Common Issues and Solutions

### Poor Convergence

**Symptoms**: High Rhat, low n.eff, wandering chains

**Solutions**:
1. More iterations: `n.iter = 20000`
2. Longer burn-in: `n.burnin = 10000`
3. More chains: `n.chains = 4`
4. Thin more: `n.thin = 5`
5. Check model specification

### D-Separation Failures

**Symptoms**: Low P(~0) values

**Solutions**:
1. Add missing paths
2. Check for confounders
3. Consider latent variables
4. Re-examine causal assumptions

### Unrealistic Estimates

**Symptoms**: Huge effects, wrong signs

**Solutions**:
1. Check data coding
2. Standardize predictors
3. Check for outliers
4. Simpler model first

### Slow Computation

**Solutions**:
1. Fewer iterations (exploratory phase)
2. Parallel chains: `parallel = TRUE`
3. Optimization mode (phylogenetic): `optimise = TRUE`
4. Reduce tree size

---

## Reporting Results

### Essential Information

1. **Model specification**: Equations, distributions
2. **Sample size**: Number of observations
3. **MCMC settings**: Chains, iterations, burn-in, thin
4. **Convergence**: All Rhat < 1.1
5. **Parameter estimates**: Mean, 95% CI
6. **Model fit**: DIC/WAIC, d-separation results
7. **Software**: phybaseR version, R version

### Example

> "We fitted a phylogenetic SEM using phybaseR (v1.0) with 3 chains of 10,000 iterations (5,000 burn-in, thin = 2). Convergence was confirmed (all Rhat < 1.05). D-separation tests indicated good model fit (all P > 0.4). Body size had a positive effect on range size (β = 0.45, 95% CI: 0.32-0.58)."

---

## Best Practices Checklist

✓ **Always check convergence** (Rhat < 1.1)  
✓ **Run d-separation tests** (validate structure)  
✓ **Use appropriate distributions** (match data type)  
✓ **Compare models** if multiple hypotheses  
✓ **Report uncertainty** (credible intervals)  
✓ **Visualize** (trace plots, parameter plots)  
✓ **Document** (settings, version, sample size)  

---

## See Also

- **[Getting Started](getting_started.html)** - Basic workflow
- **[Phylogenetic Models](phylogenetic_models.html)** - Tree-based models  
- **[Advanced Models](advanced_models.html)** - Complex specifications
- **[Latent Variables](latent_variables.html)** - M-separation
