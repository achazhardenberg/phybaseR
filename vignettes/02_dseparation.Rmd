---
title: "D-Separation and Causal Inference"
author: "Achaz von Hardenberg"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{02. D-Separation and Causal Inference}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
    collapse = TRUE,
    comment = "#>"
)
```

# D-Separation and Causal Inference

**D-separation (Shipley, 2000, 2003) is the foundation of causal inference in because.** It tests whether your hypothesized causal model correctly represents the conditional independencies in your data.

### The Problem with Correlations
In the simple linear regression presented as an example in the previous vignette, we modeled the relationship between two variables, X and Y. However, regression only tells us about correlations, not causation. We can only say that X is related to Y or also that X predicts Y, but we cannot say that X causes Y. There are indeed three reasons why X and Y could correlate (if this was real data of course, and not data we simulated with a predefined correlation!):

1. **X → Y**: X causes Y
2. **Y → X**: Y causes X  
3. **X ← Z → Y**: There is a common cause Z causing both. 

The problem is that correlation alone cannot distinguish between these three scenarios.

Let's look at a classic example A correlative study trying to establish if storks deliver babies (Matthews, 2000). we investigated this example previously in Gonzalez-Voyer & von Hardenberg (2014), and the data and a tutorial analysing this example with traditional path analysis is available as supplementary materials to that book chapter and here: https://github.com/achazhardenberg/mpcm-OPM. 

Let's download the data and take a look:
```{r}
# load data
data("storks.dat")
# rename to stork_data for consistency with rest of vignette
stork_data <- storks.dat
```


### The Solution: Causal DAGs

Directed Acyclic Graphs (DAGs) explicitly state your causal assumptions:





---

## What is D-Separation?

**D-separation** (directional separation): A rule to determine which variables should be conditionally independent given your causal DAG.

### Basic Idea

Your DAG implies certain conditional independencies. If your model is correct, these should hold in the data.

**Because tests this**:
- Derives implied independencies from your DAG
- Tests each one in your data
- Reports whether model fits

### Simple Example

```{r, eval=FALSE}
# Hypothesized model: X → Z → Y
equations <- list(
    z ~ x,
    y ~ z
)

# DAG implies: X ⊥ Y | Z
# "X and Y are independent given Z"
```

**Test**: Is this true in the data?

```{r, eval=FALSE}
fit <- because(
    equations = equations,
    data = data,
    dsep = TRUE # Test d-separation!
)
```

**Output**:
```
D-separation Tests
==================
            Test     Parameter Estimate P(~0)
 y _||_ x | {z}  beta_y_x      0.02    0.68   ✓
```

**Interpretation**: Independence holds! Model is consistent with data.

---

## The Three Path Rules

D-separation uses three rules to determine if variables are independent:

### 1. Chains (Mediators)

```
X → Z → Y
```

**Rule**: X ⊥ Y | Z (conditioning on Z blocks the path)

**Example**: Rain → Grass → Cows
- Rain affects cows *through* grass
- Given grass height, rain doesn't directly affect cows

### 2. Forks (Common Causes)

```
X ← Z → Y
```

**Rule**: X ⊥ Y | Z (conditioning on Z blocks the path)

**Example**: Heat ← Summer → Drowning
- Summer causes both
- Given season, heat doesn't affect drowning

### 3. Colliders (Common Effects)

```
X → Z ← Y
```

**Rule**: X ⊥ Y (unconditionally!)

**But**: X dependent on Y | Z (conditioning *opens* the path!)

**Example**: Skill → NBA_selection ← Height
- Skill and height are independent in general population
- But among NBA players (conditioning on selection), they're negatively correlated!

---

## Reading D-Separation Results

### Output Format

```
D-separation Tests
==================
                Test     Parameter Estimate LowerCI UpperCI Indep P(~0)
 y _||_ x | {z}  beta_y_x      0.02   -0.05   0.09   Yes   0.68
```

### Key Columns

**Test**: The conditional independence being tested
- `y _||_ x | {z}`: "y independent of x given z"
- `_||_`: Independence symbol
- `| {}`: Conditioning set (what we're controlling for)

**Parameter**: What because actually estimates
- For `y _||_ x | z`, tests `beta_y_x` in model `y ~ x + z`
- If independent, beta should be ~0

**Indep**: Is independence supported?
- `Yes`: Variables are independent (good!)
- `No`: Variables are dependent (potential problem)

**P(~0)**: Probability effect crosses zero
- **High (>0.5)**: Likely independent ✅
- **Low (<0.1)**: Likely dependent ⚠️

### Interpreting Results

#### ✅ Test Passes

```
 y _||_ x | {z}  beta_y_x  0.01  P(~0) = 0.85
```

**Meaning**: y and x are independent given z (as predicted!)  
**Conclusion**: Model is consistent with this independence

#### ❌ Test Fails

```
 y _||_ x | {z}  beta_y_x  0.45  P(~0) = 0.02
```

**Meaning**: y and x are dependent even after controlling for z  
**Conclusion**: Model predicts independence but data shows dependence  
**Action needed**: Model is misspecified!

---

## Common Misspecification Patterns

### Missing Direct Path

**Model**:
```
X → Z → Y
```

**D-sep test**:
```
y _||_ x | {z}  → FAIL (P < 0.05)
```

**Problem**: X has direct effect on Y too!

**Fix**:
```
X → Z → Y
X --------→ Y  (add direct path)
```

### Reversed Causality

**Model**:
```
X → Y
```

**D-sep test**:
```
(No unconditional independencies to test)
```

**Better test**: Compare to reversed model
```
Y → X
```
Use DIC/WAIC to compare.

### Unmeasured Confounder

**Model**:
```
X → Y
```

**D-sep**: Passes (no implied independencies)

**But**: Actually `X ← Z → Y` (Z unmeasured)

**Can't detect with d-sep!** Need:
1. Theory
2. Additional variables
3. Experimental manipulation

---

## Practical Workflow

### 1. Specify Your Causal Model

```{r, eval=FALSE}
# Based on theory, not data!
equations <- list(
    range_size ~ body_size,
    population ~ range_size + body_size
)
```

### 2. Fit Model with D-Separation

```{r, eval=FALSE}
fit <- because(
    equations = equations,
    data = data,
    dsep = TRUE, # Critical!
    n.chains = 3,
    n.iter = 5000
)
```

### 3. Check D-Separation Results

```{r, eval=FALSE}
summary(fit)
```

Look at d-separation section:
- All P(~0) > 0.1? ✓ Model fits
- Some P(~0) < 0.05? Investigate

### 4. Diagnose Failures

If test fails:

1. **Which variables?** Identify failing independence
2. **Why?** Missing path? Confounder? Wrong direction?
3. **Theory?** Is there a causal reason for dependence?
4. **Revise**: Update model based on theory + results

### 5. Re-test

```{r, eval=FALSE}
# Updated model
equations_v2 <- list(
    range_size ~ body_size,
    population ~ range_size + body_size,
    dispersal ~ body_size # Added!
)

fit_v2 <- because(equations_v2, data, dsep = TRUE)
```

Iterate until d-separation tests pass!

---

## Important Distinctions

### D-Separation vs Model Fit

**Traditional SEM "fit indices"**: RMSEA, CFI, etc.
- Only for measurement models
- Not for causal inference

**D-separation**:
- Tests causal structure
- Directly interpretable
- Based on independence, not correlations

### D-Separation vs Significance Testing

**Not** testing if effects are "significant"!

**Testing**: Are independencies implied by DAG present in data?

**Example**:
```
Range ~ Body (significant, p < 0.01)
Pop ~ Range (significant, p < 0.01)  
Pop ~ Body | Range (non-significant, p = 0.8)  ← D-sep test!
```

Last test checks if direct Body→Pop path is needed.

---

## Limitations of D-Separation

### What D-Sep CAN Tell You

- Model is **inconsistent** with data (test fails)  
- Specific independencies that don't hold  
- Which paths may be missing  

### What D-Sep CANNOT Tell You

- Model is **correct** (only consistent)  
- Causal direction (X→Y vs Y→X may fit equally)  
- Presence of unmeasured confounders  
- Whether effects are "real" vs spurious  

**Key**: D-separation can **reject** models but can't **prove** them correct. Multiple models may be consistent with data.

---

## Advanced Topic: Basis Sets

### What is a Basis Set?

The **minimal set** of conditional independencies implied by your DAG.

**Because automatically**:
1. Derives basis set from your equations
2. Converts each independence to a testable model
3. Runs tests
4. Reports results

You don't need to derive basis sets manually!

### Example

**DAG**:
```
X → Z → Y
X → Y
W → Y
```

**Basis set**:
```
1. W _||_ X
2. W _||_ Z | {X}
```

Only need to test these 2! Other independencies are implied.

---

## Next Steps

Now that you understand d-separation:

1. **[Phylogenetic Models](03_phylogenetic_models.html)** - Apply to comparative data
2. **[Advanced Models](06_advanced_models.html)** - Complex model specifications  
3. **[Latent Variables](08_latent_variables.html)** - M-separation extends d-separation
4. **[Model Diagnostics](09_model_diagnostics.html)** - Detailed interpretation

---

## Key Takeaways

1. **D-separation tests causal models** - Not just correlations
2. **High P(~0) = good** - Independence holds as predicted
3. **Failures reveal problems** - Missing paths, confounders
4. **Iterate!** - Revise model, retest, repeat
5. **Theory first** - D-separation tests theory, doesn't generate it

**D-separation makes because a tool for causal inference, not just correlation analysis.**

## References

Gonzalez-Voyer, A., & von Hardenberg, A. (2014). **An introduction to phylogenetic path analysis.** In Modern phylogenetic comparative methods and their application in evolutionary biology: Concepts and practice (pp. 201-229). Springer Berlin Heidelberg.

Matthews, R. (2000). Storks deliver babies (p= 0.008). **Teaching Statistics**, 22(2), 36-38.

Shipley, B. (2000). A New Inferential Test for Path Models Based on Directed Acyclic Graphs. **Structural Equation Modeling: A Multidisciplinary Journal**, 7(2), 206–218. https://doi.org/10.1207/S15328007SEM0702_4

Shipley, B. (2003). Testing recursive path models with correlated errors using d-separation. **Structural Equation Modeling**, 10(2), 214-221.
